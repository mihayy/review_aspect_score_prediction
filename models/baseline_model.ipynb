{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mihayy/review_aspect_score_prediction/blob/master/models/baseline_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RJEutDSR595",
        "colab_type": "text"
      },
      "source": [
        "# Baseline Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaSd4E5gU8qe",
        "colab_type": "code",
        "outputId": "da0a6986-cd9b-4989-9a1f-fde012732f5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "from functools import partial\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vmy4qhobp18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import log_loss, accuracy_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAL0bJnFx7OL",
        "colab_type": "code",
        "outputId": "01e00ab1-b5f1-45ed-a81c-c629a678cc95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at gdrive; to attempt to forcibly remount, call drive.mount(\"gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH7RLrf8U8qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Config(object):\n",
        "  def __init__(self):\n",
        "    self.gdrive_working_dir = Path(\"gdrive/My Drive/thesis\")\n",
        "\n",
        "    self.embeddings_path = self.gdrive_working_dir/ \"embeddings\"\n",
        "\n",
        "#     self.dataset_intermediate_path = Path(\"manual_labeled_strength_weak_sections/summary_strength_weak_sections/clarity_sentences/mandatory_clarity_sentences\")\n",
        "    self.dataset_intermediate_path = Path(\"\")\n",
        "\n",
        "#     self.dataset_intermediate_path = Path(\"manual_labeled_strength_weak_sections\")\n",
        "#     self.dataset_intermediate_path = Path(\"acl_abstracts\")\n",
        "    self.dataset_path = self.gdrive_working_dir/ \"data\" / self.dataset_intermediate_path\n",
        "\n",
        "    self.train_dataset_filename = \"train_dataset.csv\"\n",
        "    self.dev_dataset_filename = \"dev_dataset.csv\"\n",
        "    self.test_dataset_filename = \"acl_dev_test.csv\"\n",
        "    \n",
        "    self.train_ds = \"train_ds_\"\n",
        "    self.test_ds = \"test_ds_\"\n",
        "\n",
        "    self.aspects_no_com_approp = ['RECOMMENDATION', 'REVIEWER_CONFIDENCE', 'SOUNDNESS_CORRECTNESS', 'IMPACT', 'SUBSTANCE', 'CLARITY', 'ORIGINALITY']\n",
        "    \n",
        "    self.stats_path = self.gdrive_working_dir / \"simple_stats_random\"\n",
        "#     self.stats_path = Path(\"\")\n",
        "    \n",
        "  def set_dataset_intermediate_path(self, intermediate_path):\n",
        "    self.dataset_intermediate_path = intermediate_path\n",
        "    self.dataset_path = self.gdrive_working_dir/ \"data\" / self.dataset_intermediate_path\n",
        "    \n",
        "  def set_ds_fname(self, iteration):\n",
        "    self.train_dataset_filename = self.train_ds + str(iteration) + \".csv\"\n",
        "    self.dev_dataset_filename = self.test_ds + str(iteration) + \".csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGb6APcqEjhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env_var = Config()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBd-aeTmGPai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_intermediate_paths =[Path(\"\"),\n",
        "                             Path(\"strength_weak_sections\"),\n",
        "                             Path(\"manual_labeled_strength_weak_sections\"),\n",
        "                             Path(\"manual_labeled_strength_weak_sections/first_section\"),\n",
        "                             Path(\"manual_labeled_strength_weak_sections/strength_weak_sections\"),\n",
        "                             Path(\"manual_labeled_strength_weak_sections/strength_weak_sections_len_limit\"),\n",
        "                             Path(\"manual_labeled_strength_weak_sections/summary_strength_weak_sections\"),\n",
        "                             Path(\"manual_labeled_strength_weak_sections/summary_strength_weak_sections/clarity_sentences\"),\n",
        "                             Path(\"manual_labeled_strength_weak_sections/weak_section\"),\n",
        "                             Path(\"manual_labeled_strength_weak_sections/weak_strength_sections_len_limit\"),\n",
        "                             Path(\"manual_labeled_strength_weak_sections/aug_stren_weak_sections_len_limit\"),\n",
        "                             Path(\"manual_labeled_strength_weak_sections/strength_section\"),\n",
        "                             Path(\"acl_abstracts\")\n",
        "                            ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubRKBZa6RwtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import operator\n",
        "\n",
        "class Stat():\n",
        "  def __init__(self, epoch, dev_accuracy, dev_loss, dev_conf_matrix, iteration):\n",
        "    self.epoch = epoch    \n",
        "    self.dev_accuracy = dev_accuracy\n",
        "    self.dev_loss = dev_loss\n",
        "    self.dev_conf_matrix = dev_conf_matrix\n",
        "    self.iteration = iteration\n",
        "    \n",
        "  def __str__(self):\n",
        "    return f'{self.epoch} Test accuracy: {self.dev_accuracy} Test loss: {self.dev_loss}'\n",
        "\n",
        "class Model_stats(object):\n",
        "  def __init__(self, dataset_intermediate_path, aspect_label_name):\n",
        "    self.dataset_intermediate_path = dataset_intermediate_path\n",
        "    self.aspect_label_name = aspect_label_name\n",
        "    self.stats = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5ttDxp2Rwr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "class Stats_Manager(object):\n",
        "  def __init__(self, stats_runs_path):\n",
        "    self.stats_runs_path = stats_runs_path\n",
        "    self.models_stats = []\n",
        "    \n",
        "  def update(self):\n",
        "    with open(self.stats_runs_path, \"wb\") as output_file:\n",
        "      pickle.dump(self.models_stats, output_file)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8Fu4Xnq9Rqn",
        "colab_type": "code",
        "outputId": "e84c2f09-c475-4f90-dae5-6496e64b8e23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "models_stats = []\n",
        "\n",
        "iterations = 10\n",
        "\n",
        "stats_runs_path = env_var.stats_path / \"rf_stats.p\"\n",
        "mv_runs_path = env_var.stats_path / \"mv_stats.p\"\n",
        "\n",
        "stats_manager = Stats_Manager(stats_runs_path)\n",
        "stats_manager_mv = Stats_Manager(mv_runs_path)\n",
        "\n",
        "for path_idx, ds_inter_path in enumerate(dataset_intermediate_paths):\n",
        "  \n",
        "  env_var.set_dataset_intermediate_path(ds_inter_path)  \n",
        "  print(env_var.dataset_intermediate_path)  \n",
        "  \n",
        "  model_stats_for_inter_path = [Model_stats(ds_inter_path, aspect_label_name) for aspect_label_name in env_var.aspects_no_com_approp]\n",
        "  mv_stats_for_inter_path = [Model_stats(ds_inter_path, aspect_label_name) for aspect_label_name in env_var.aspects_no_com_approp]\n",
        "  \n",
        "  for iteration in range(iterations):\n",
        "    env_var.set_ds_fname(iteration)\n",
        "    \n",
        "    df_train = pd.read_csv(env_var.dataset_path / env_var.train_dataset_filename)\n",
        "    df_test = pd.read_csv(env_var.dataset_path / env_var.dev_dataset_filename)\n",
        "\n",
        "    count_vectorizer = TfidfVectorizer(\n",
        "      analyzer=\"word\", tokenizer=nltk.word_tokenize,\n",
        "      preprocessor=None, stop_words='english', max_features=None)    \n",
        "\n",
        "    svd = TruncatedSVD(n_components=25, n_iter=25, random_state=0)\n",
        "\n",
        "    X_train = count_vectorizer.fit_transform(df_train['comments'])\n",
        "    X_test = count_vectorizer.transform(df_test['comments'])\n",
        "\n",
        "    X_train = svd.fit_transform(X_train)\n",
        "\n",
        "    X_test = svd.transform(X_test)\n",
        "    \n",
        "    for aspect_idx, aspect in enumerate(env_var.aspects_no_com_approp):\n",
        "      \n",
        "      y_train = df_train[aspect].values.ravel()\n",
        "      y_test = df_test[aspect].values.ravel()\n",
        "\n",
        "      rf_clf = RandomForestClassifier(n_estimators=400, max_depth=3)\n",
        "      rf_clf.fit(X_train, y_train)\n",
        "      rf_acc = rf_clf.score(X_test, y_test) \n",
        "      \n",
        "      stat = Stat(0, rf_acc, 0, [], iteration)\n",
        "      model_stats_for_inter_path[aspect_idx].stats.append(stat)\n",
        "      \n",
        "      items, counts = np.unique(y_train, return_counts=True)\n",
        "      y_pred = [items[np.argmax(counts)]] * len(y_test)\n",
        "      mv_acc = accuracy_score(y_test, y_pred)\n",
        "      \n",
        "      mv_stat = Stat(0, mv_acc, 0, [], iteration)\n",
        "      mv_stats_for_inter_path[aspect_idx].stats.append(mv_stat)\n",
        "      \n",
        "  stats_manager.models_stats += model_stats_for_inter_path\n",
        "  \n",
        "  stats_manager_mv.models_stats += mv_stats_for_inter_path\n",
        "\n",
        "stats_manager.update()\n",
        "stats_manager_mv.update()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".\n",
            "strength_weak_sections\n",
            "manual_labeled_strength_weak_sections\n",
            "manual_labeled_strength_weak_sections/first_section\n",
            "manual_labeled_strength_weak_sections/strength_weak_sections\n",
            "manual_labeled_strength_weak_sections/strength_weak_sections_len_limit\n",
            "manual_labeled_strength_weak_sections/summary_strength_weak_sections\n",
            "manual_labeled_strength_weak_sections/summary_strength_weak_sections/clarity_sentences\n",
            "manual_labeled_strength_weak_sections/weak_section\n",
            "manual_labeled_strength_weak_sections/weak_strength_sections_len_limit\n",
            "manual_labeled_strength_weak_sections/aug_stren_weak_sections_len_limit\n",
            "manual_labeled_strength_weak_sections/strength_section\n",
            "acl_abstracts\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}